<!DOCTYPE html>
<html lang="en"><head>
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="viewport" content="width=device-width, initial-scale=1"><!-- Begin Jekyll SEO tag v2.8.0 -->
<title>Inference | üêπ HipGPT</title>
<meta name="generator" content="Jekyll v4.3.4" />
<meta property="og:title" content="Inference" />
<meta name="author" content="Aarne Talman" />
<meta property="og:locale" content="en_US" />
<link rel="canonical" href="http://localhost:4000/inference/" />
<meta property="og:url" content="http://localhost:4000/inference/" />
<meta property="og:site_name" content="üêπ HipGPT" />
<meta property="og:type" content="website" />
<meta name="twitter:card" content="summary" />
<meta property="twitter:title" content="Inference" />
<script type="application/ld+json">
{"@context":"https://schema.org","@type":"WebPage","author":{"@type":"Person","name":"Aarne Talman"},"headline":"Inference","url":"http://localhost:4000/inference/"}</script>
<!-- End Jekyll SEO tag -->
<link id="main-stylesheet" rel="stylesheet" href="/assets/css/style.css">
  <link rel="stylesheet" href="/assets/css/custom.css"><link type="application/atom+xml" rel="alternate" href="http://localhost:4000/feed.xml" title="üêπ HipGPT" />
</head>
<body><header class="site-header">

  <div class="wrapper">
    <a class="site-title" rel="author" href="/">üêπ HipGPT</a>
      <nav class="site-nav">
        <input type="checkbox" id="nav-trigger" />
        <label for="nav-trigger">
          <span class="menu-icon"></span>
        </label>

        <div class="nav-items">
  <a class="nav-item" href="/">Home</a>
  <a class="nav-item" href="/getting-started/">Getting Started</a>
  <a class="nav-item" href="/training/">Training</a>
  <a class="nav-item" href="/inference/">Inference</a>
  <a class="nav-item" href="/codebase/">Codebase</a>
  <a class="nav-item" href="/license/">License</a>
</div>

      </nav>
  </div>
</header>
<main class="page-content" aria-label="Content">
      <div class="wrapper">
        <h1 id="inference">Inference</h1>

<p>This section provides instructions and details on how to use a trained GPT model to generate new text. Inference, or text generation, is handled by the <code class="language-plaintext highlighter-rouge">generate</code> executable.</p>

<h2 id="1-how-text-generation-works">1. How Text Generation Works</h2>

<p>Text generation is an iterative process. The model starts with a prompt and predicts the most likely next token based on the input sequence. This newly generated token is then added to the sequence, and the process repeats. This continues until the desired number of new tokens (<code class="language-plaintext highlighter-rouge">--num_tokens</code>) is reached or an end-of-sequence token (<code class="language-plaintext highlighter-rouge">--eos_id</code>) is generated.</p>

<p>The <code class="language-plaintext highlighter-rouge">generate</code> executable loads the trained model configuration and weights from a training run directory. It automatically resolves the tokenizer and checkpoint paths based on the run configuration. The <code class="language-plaintext highlighter-rouge">GPTModel::generate</code> method handles the core generation loop, which includes:</p>

<ul>
  <li>Calling the forward pass of the model to get logits for the next token</li>
  <li>Applying repetition penalty to reduce repeated tokens</li>
  <li>Temperature scaling for controlling randomness</li>
  <li>Top_k and top_p (nucleus) filtering for improved sampling quality</li>
  <li>Sampling the next token from the filtered probability distribution</li>
  <li>Appending the new token to the sequence</li>
</ul>

<p>For efficiency, the <code class="language-plaintext highlighter-rouge">generate</code> executable only feeds the most recent tokens up to <code class="language-plaintext highlighter-rouge">max_seq_len</code> into the model‚Äôs forward pass during each step, using a sliding window approach.</p>

<h2 id="2-generating-text">2. Generating Text</h2>

<h3 id="using-run-based-configuration">Using Run-Based Configuration</h3>

<p>The recommended way to generate text is using the new run-based system with automatic configuration loading:</p>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c"># Generate using the latest checkpoint from a training run</span>
./build/generate <span class="nt">--prompt</span> <span class="s2">"To be, or not to be:"</span> <span class="nt">--run-name</span> shakespeare_v1
</code></pre></div></div>

<p>You can also specify a particular training step:</p>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c"># Use a specific checkpoint step</span>
./build/generate <span class="nt">--prompt</span> <span class="s2">"Once upon a time"</span> <span class="nt">--run-name</span> shakespeare_v1 <span class="nt">--step</span> 1500
</code></pre></div></div>

<h3 id="advanced-generation-examples">Advanced Generation Examples</h3>

<p>Control the creativity and quality of generation with sampling parameters:</p>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c"># Conservative, focused generation</span>
./build/generate <span class="nt">--prompt</span> <span class="s2">"The meaning of life is"</span> <span class="se">\</span>
  <span class="nt">--run-name</span> philosophy_model <span class="se">\</span>
  <span class="nt">--num_tokens</span> 100 <span class="se">\</span>
  <span class="nt">--temp</span> 0.7 <span class="se">\</span>
  <span class="nt">--top_k</span> 20 <span class="se">\</span>
  <span class="nt">--top_p</span> 0.9 <span class="se">\</span>
  <span class="nt">--rep-penalty</span> 1.1

<span class="c"># Creative, diverse generation  </span>
./build/generate <span class="nt">--prompt</span> <span class="s2">"In a galaxy far away"</span> <span class="se">\</span>
  <span class="nt">--run-name</span> scifi_model <span class="se">\</span>
  <span class="nt">--num_tokens</span> 200 <span class="se">\</span>
  <span class="nt">--temp</span> 1.2 <span class="se">\</span>
  <span class="nt">--top_k</span> 50 <span class="se">\</span>
  <span class="nt">--top_p</span> 0.95
</code></pre></div></div>

<h3 id="streaming-output">Streaming Output</h3>

<p>Generated text is displayed token by token as it‚Äôs produced, providing real-time feedback during generation.</p>

<h2 id="3-configuration-resolution">3. Configuration Resolution</h2>

<p>The <code class="language-plaintext highlighter-rouge">generate</code> executable automatically resolves file paths based on your training run:</p>

<h3 id="automatic-path-resolution">Automatic Path Resolution</h3>
<ul>
  <li><strong>Config File</strong>: Uses <code class="language-plaintext highlighter-rouge">latest_config.json</code> by default, or <code class="language-plaintext highlighter-rouge">[run-name]_step[N]_config.json</code> if <code class="language-plaintext highlighter-rouge">--step</code> is specified</li>
  <li><strong>Checkpoint</strong>: Automatically loads the corresponding <code class="language-plaintext highlighter-rouge">.bin</code> file referenced in the config</li>
  <li><strong>Tokenizer</strong>: Uses the tokenizer path from the configuration file</li>
</ul>

<h3 id="run-directory-structure">Run Directory Structure</h3>
<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>checkpoints/[run-name]/
‚îú‚îÄ‚îÄ tokenizer.json                    # ‚Üê Auto-loaded
‚îú‚îÄ‚îÄ tokens.bin  
‚îú‚îÄ‚îÄ [run-name]_step1000.bin          # ‚Üê Model weights
‚îú‚îÄ‚îÄ [run-name]_step1000_config.json  # ‚Üê Configuration
‚îú‚îÄ‚îÄ latest_checkpoint.bin ‚Üí [symlink]
‚îî‚îÄ‚îÄ latest_config.json ‚Üí [symlink]   # ‚Üê Default config
</code></pre></div></div>

<h2 id="4-command-line-flags-explained">4. Command-Line Flags Explained</h2>

<p>The <code class="language-plaintext highlighter-rouge">generate</code> executable is used to produce new text from a trained model with advanced sampling capabilities.</p>

<h3 id="required-parameters">Required Parameters</h3>

<table>
  <thead>
    <tr>
      <th style="text-align: left">Flag</th>
      <th style="text-align: left">Type</th>
      <th style="text-align: left">Default</th>
      <th style="text-align: left">Description</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td style="text-align: left"><code class="language-plaintext highlighter-rouge">--prompt</code></td>
      <td style="text-align: left"><code class="language-plaintext highlighter-rouge">string</code></td>
      <td style="text-align: left"><em>(required)</em></td>
      <td style="text-align: left">The initial text sequence for the model to continue. Enclose prompts with spaces in quotation marks.</td>
    </tr>
    <tr>
      <td style="text-align: left"><code class="language-plaintext highlighter-rouge">--run-name</code></td>
      <td style="text-align: left"><code class="language-plaintext highlighter-rouge">string</code></td>
      <td style="text-align: left"><em>(required)</em></td>
      <td style="text-align: left">Name of the training run to use for generation. Loads configuration from <code class="language-plaintext highlighter-rouge">checkpoints/[run-name]/</code>.</td>
    </tr>
  </tbody>
</table>

<h3 id="run-and-checkpoint-selection">Run and Checkpoint Selection</h3>

<table>
  <thead>
    <tr>
      <th style="text-align: left">Flag</th>
      <th style="text-align: left">Type</th>
      <th style="text-align: left">Default</th>
      <th style="text-align: left">Description</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td style="text-align: left"><code class="language-plaintext highlighter-rouge">--step</code></td>
      <td style="text-align: left"><code class="language-plaintext highlighter-rouge">int</code></td>
      <td style="text-align: left"><em>(latest)</em></td>
      <td style="text-align: left">Specific training step to load. If not specified, uses the latest available checkpoint.</td>
    </tr>
  </tbody>
</table>

<h3 id="generation-parameters">Generation Parameters</h3>

<table>
  <thead>
    <tr>
      <th style="text-align: left">Flag</th>
      <th style="text-align: left">Type</th>
      <th style="text-align: left">Default</th>
      <th style="text-align: left">Description</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td style="text-align: left"><code class="language-plaintext highlighter-rouge">--num_tokens</code></td>
      <td style="text-align: left"><code class="language-plaintext highlighter-rouge">int</code></td>
      <td style="text-align: left"><code class="language-plaintext highlighter-rouge">100</code></td>
      <td style="text-align: left">The number of new tokens to generate after the prompt.</td>
    </tr>
    <tr>
      <td style="text-align: left"><code class="language-plaintext highlighter-rouge">--max_seq_len</code></td>
      <td style="text-align: left"><code class="language-plaintext highlighter-rouge">int</code></td>
      <td style="text-align: left"><code class="language-plaintext highlighter-rouge">256</code></td>
      <td style="text-align: left">The host-side context window size used during generation. Should match training configuration.</td>
    </tr>
    <tr>
      <td style="text-align: left"><code class="language-plaintext highlighter-rouge">--eos_id</code></td>
      <td style="text-align: left"><code class="language-plaintext highlighter-rouge">int</code></td>
      <td style="text-align: left"><code class="language-plaintext highlighter-rouge">-1</code></td>
      <td style="text-align: left">The end-of-sequence token ID. Generation will stop if this token is produced. Set to <code class="language-plaintext highlighter-rouge">-1</code> to disable.</td>
    </tr>
  </tbody>
</table>

<h3 id="sampling-control">Sampling Control</h3>

<table>
  <thead>
    <tr>
      <th style="text-align: left">Flag</th>
      <th style="text-align: left">Type</th>
      <th style="text-align: left">Default</th>
      <th style="text-align: left">Description</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td style="text-align: left"><code class="language-plaintext highlighter-rouge">--top_k</code></td>
      <td style="text-align: left"><code class="language-plaintext highlighter-rouge">int</code></td>
      <td style="text-align: left"><code class="language-plaintext highlighter-rouge">50</code></td>
      <td style="text-align: left">Restricts sampling to the top k most likely tokens. Higher values increase diversity. Set to <code class="language-plaintext highlighter-rouge">0</code> to disable.</td>
    </tr>
    <tr>
      <td style="text-align: left"><code class="language-plaintext highlighter-rouge">--temp</code></td>
      <td style="text-align: left"><code class="language-plaintext highlighter-rouge">float</code></td>
      <td style="text-align: left"><code class="language-plaintext highlighter-rouge">0.8</code></td>
      <td style="text-align: left">Sampling temperature. Lower values (0.7) make output more focused, higher values (1.3) increase creativity.</td>
    </tr>
    <tr>
      <td style="text-align: left"><code class="language-plaintext highlighter-rouge">--top_p</code></td>
      <td style="text-align: left"><code class="language-plaintext highlighter-rouge">float</code></td>
      <td style="text-align: left"><code class="language-plaintext highlighter-rouge">0.9</code></td>
      <td style="text-align: left">Nucleus sampling threshold. Dynamically adjusts the number of tokens considered based on cumulative probability.</td>
    </tr>
    <tr>
      <td style="text-align: left"><code class="language-plaintext highlighter-rouge">--rep-penalty</code></td>
      <td style="text-align: left"><code class="language-plaintext highlighter-rouge">float</code></td>
      <td style="text-align: left"><code class="language-plaintext highlighter-rouge">1.1</code></td>
      <td style="text-align: left">Repetition penalty applied to previously generated tokens. Values &gt; 1.0 reduce repetition.</td>
    </tr>
  </tbody>
</table>

<h2 id="5-sampling-strategies">5. Sampling Strategies</h2>

<p>HipGPT implements multiple advanced sampling techniques that work together:</p>

<h3 id="temperature-scaling">Temperature Scaling</h3>
<p>Controls the randomness of predictions:</p>
<ul>
  <li><code class="language-plaintext highlighter-rouge">temp &lt; 1.0</code>: More deterministic, focused output</li>
  <li><code class="language-plaintext highlighter-rouge">temp = 1.0</code>: Unmodified model probabilities</li>
  <li><code class="language-plaintext highlighter-rouge">temp &gt; 1.0</code>: More random, creative output</li>
</ul>

<h3 id="top-k-sampling">Top-k Sampling</h3>
<p>Restricts consideration to the k most probable tokens:</p>
<ul>
  <li>Prevents extremely unlikely tokens from being selected</li>
  <li>Higher k values allow more diversity</li>
</ul>

<h3 id="top_p-nucleus-sampling">Top_p (Nucleus) Sampling</h3>
<p>Dynamically selects tokens based on cumulative probability:</p>
<ul>
  <li>More adaptive than top-k for different contexts</li>
  <li>Maintains quality while allowing flexibility</li>
</ul>

<h3 id="repetition-penalty">Repetition Penalty</h3>
<p>Reduces repetitive output by penalizing recently used tokens:</p>
<ul>
  <li>Applied before temperature scaling</li>
  <li>Values between 1.05-1.15 typically work well</li>
</ul>

<h2 id="6-performance-optimizations">6. Performance Optimizations</h2>

<p>The generation pipeline includes several performance enhancements:</p>

<ul>
  <li><strong>Efficient Memory Management</strong>: Reuses GPU buffers across generation steps</li>
  <li><strong>Sliding Window Context</strong>: Maintains fixed-size context window for long generations</li>
  <li><strong>Host-Side Sampling</strong>: CPU-based sampling reduces GPU-CPU transfers</li>
  <li><strong>Vectorized Operations</strong>: Optimized probability computations</li>
</ul>

<h2 id="7-example-workflows">7. Example Workflows</h2>

<h3 id="quick-test-generation">Quick Test Generation</h3>
<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c"># Fast test with a simple prompt</span>
./build/generate <span class="nt">--prompt</span> <span class="s2">"Hello world"</span> <span class="nt">--run-name</span> test_run <span class="nt">--num_tokens</span> 20
</code></pre></div></div>

<h3 id="high-quality-story-generation">High-Quality Story Generation</h3>
<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c"># Focused narrative generation</span>
./build/generate <span class="se">\</span>
  <span class="nt">--prompt</span> <span class="s2">"The old wizard looked into the crystal ball and saw"</span> <span class="se">\</span>
  <span class="nt">--run-name</span> fantasy_model <span class="se">\</span>
  <span class="nt">--num_tokens</span> 150 <span class="se">\</span>
  <span class="nt">--temp</span> 0.8 <span class="se">\</span>
  <span class="nt">--top_k</span> 30 <span class="se">\</span>
  <span class="nt">--top_p</span> 0.92 <span class="se">\</span>
  <span class="nt">--rep-penalty</span> 1.08
</code></pre></div></div>

<h3 id="creative-exploration">Creative Exploration</h3>
<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c"># High creativity for brainstorming</span>
./build/generate <span class="se">\</span>
  <span class="nt">--prompt</span> <span class="s2">"Imagine a world where"</span> <span class="se">\</span>
  <span class="nt">--run-name</span> creative_model <span class="se">\</span>
  <span class="nt">--num_tokens</span> 100 <span class="se">\</span>
  <span class="nt">--temp</span> 1.3 <span class="se">\</span>
  <span class="nt">--top_k</span> 100 <span class="se">\</span>
  <span class="nt">--top_p</span> 0.95 <span class="se">\</span>
  <span class="nt">--rep-penalty</span> 1.05
</code></pre></div></div>

      </div>
    </main><link id="fa-stylesheet" rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@latest/css/all.min.css">

<footer class="site-footer h-card">
  <data class="u-url" value="/"></data>

  <div class="wrapper">

    <div class="footer-col-wrapper">
      <div class="footer-col">
        <ul class="contact-list">
          <li class="p-name">Aarne Talman</li>
          
        </ul>
      </div>
      <div class="footer-col">
        <p></p>
      </div>
    </div>

    <div class="social-links"><ul class="social-media-list"><li>
    <a rel="me" href="https://github.com/aarnetalman/hipgpt" target="_blank" title="HipGPT">
      <span class="grey fa-brands fa-github fa-lg"></span>
    </a>
  </li>
</ul>
</div>

  </div>

</footer>

</body>

</html>
